参考阅读：

- 《云原生安全：攻防实践与体系构建》资料仓库：https://github.com/Metarget/cloud-native-security-book

# 一、云原生安全概述

## 1 云原生安全

### 1.1 云原生及其特征

CNCF（Cloud Native Computing Foundation，云原生计算基金会）对云原生的见解：

“云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器、服务网络、微服务、不可变基础设置和声明式 API。这些技术能够构建容错性好、易于管理和便于观察的松耦合系统。结合可靠的自动化手段，云原生技术使工程师能够轻松地对系统做出频繁和可预测的重大变更。”

云原生提倡应用的敏捷、可靠、高弹性、易扩展以及持续更新。

不同于以虚拟化为基础的传统云计算系统，云原生系统一般有如下特征：

- 轻、快、不变的基础设施
- 弹性服务编排
- 开发运营一体化
- 微服务架构
- 无服务模型

云原生真正以云的模式管理和部署资源，用户看到的将不是一个个 IT 系统/虚拟主机，而是一个个业务单元，开发者只需要聚焦于业务本身。虚拟化安全关注的是资源，云原生安全关注的是应用。

微服务的设计、无服务的功能是云原生理念的核心体现，而容器、编排、服务网格均是实现云原生的支撑技术。

#### 轻、快、不变的基础设施

不变的基础设施（immutable infrastructure）：只更新镜像而不改变容器运行时的模式。

#### 弹性服务编排

服务编排（orchestration）提供了分布式的计算、存储和网络资源管理功能，可以按需、弹性地控制服务的位置、容量、版本，监控并保证业务的可访问性。

#### 开发运营一体化

开发运营一体化（DevOps）是一组将软件开发和 IT 运营相结合的实践，目标在于缩短软件开发周期，并提供高质量软件的持续交付。

#### 微服务架构

随着 Web Service 标准的推出，应用以标准的服务交付，应用见通过远程服务调用（RPC）进行交互，形成了面向服务的架构（Service-Oriented Architecture，SOA），极大提升了应用组件的标准化程度和系统集成效率。

微服务架构使得每个服务聚焦在自己的功能上，做到小而精，然后通过应用编排组装，进而实现等价于传统单体应用的复杂功能。其优点是后续业务修改时可复用现有的微服务，而不需要关心其内部实现，可最大限度地减少重构开销。

#### 无服务模型

无服务（Serverless）是一种基于代码和计算任务执行的云计算抽象模型，与之相对的是基于服务器（虚拟机、容器）的计算模式。无服务聚焦在函数计算，隐藏了底层复杂的实现方式，使开发者能够聚焦于业务本身。

无服务在公有云和私有云上都有相应的服务，如 AWS Lambda、阿里云的函数计算、Kubernetes 的 Kubeless、Apache OpenWhisk 等。

#### 1.2 面向云原生环境的安全体系

云原生安全包含两层含义：面向云原生环境的安全和具有云原生特征的安全。

根据云原生环境的构成，面向云原生环境的安全体系可包含三个层面的安全机制：容器安全、编排系统安全、云原生应用安全。

##### 容器安全

容器环境，或者叫容器云，其本质是云计算的一种实现方式，可以将其称为 PaaS（Platform as a Service） 或者 CaaS（Containers as a Service）。容器层面的安全可以分为：

1. 容器环境基础设置的安全性。例如主机上的安全配置是否会影响到其上运行的容器，主机上的安全漏洞和恶意进程是否会影响到容器，容器内的进程是否可以利用主机上的安全漏洞，等等。
2. 容器的镜像安全。例如镜像中的软件是否存在安全漏洞，镜像在构建过程中是否存在安全风险，镜像在传输过程中是否被恶意篡改，等等。
3. 容器的运行时安全。例如运行的容器间隔离是否充分，容器间的通信是否是安全的，容器内的恶意程序是否会影响到主机或者其他容器，容器的资源使用情况是否安全，等等。
4. 整个容器生态的安全性。例如 Docker 自身的安全性如何，Service Mesh/Serverless 对容器安全有什么影响，容器中安全密钥的管理与传统环境有什么不同，容器化后的数据隐私保护与传统的数据隐私保护是否一致，等等。

##### 编排系统安全

针对 Kubernetes 的攻击手段见后续章节。

##### 云原生应用安全

编排系统支撑着诸多微服务框架和云原生应用，如无服务、服务网格等，这些新型的为服务体系也同样存在各种安全风险。例如，攻击者通过编写一段无服务器的代码获得运行无服务程序容器的 shell 权限，进而对容器网络进行渗透。

## 2 云原生技术

### 2.1 容器技术

#### 容器与虚拟化

虚拟化（Virualization）和容器（Container）都是系统虚拟化的实现技术。

虚拟化通常在 Hypervisor 层实现对硬件资源的虚拟化，Hypervisor 为虚拟机提供了虚拟的运行平台，管理虚拟机的操作系统的运行平台，管理虚拟机的操作系统的运行，每个虚拟机都有自己的操作系统、系统库以及应用。

容器并没有 Hypervisor 层，每个容器是与主机共享硬件资源及操作系统。

#### 容器镜像

镜像是容器运行的基础，容器引擎服务可使用不同的镜像启动相应的容器。

与虚拟机所用的系统镜像不同，容器镜像不仅没有 Linux 系统内核，同时在格式上也有很大的区别。虚拟机镜像像是一个完整系统封装成一个镜像文件，而容器镜像不是一个文件，是分层存储的文件系统。

#### 容器存储

1. 镜像元数据：在 Linux 系统中 Docker 的数据默认存放在 /var/lib/docker 中，基于不同的系统又有不同的存储驱动和不同的目录结构。镜像每一层的 ID 是该文件内容的散列校验值，作为该层的唯一标识。
2. 存储驱动：在理想情况下，我们使用挂载卷来存储高读写的目录，很少将数据直接写入容器的可写层。针对直接写入容器可写层的特殊需求，Docker 依靠驱动技术来管理镜像与运行他们的容器间的存储和交互。目前，Docker 支持 overlay2、aufs、fuse-overlayfs、devicemapper、btrfs、zfs、vfs 等存储驱动。
3. 数据卷：Docker 采用数据卷（Volume）的形式向容器提供持久化存储。绑定挂载（Bind Mounts）依赖于主机的目录结构，但数据全是由 Docker 管理的。

#### 容器运行时

容器运行时负责管理容器运行的整个生命周期，包括但不限于指定容器镜像格式、构建镜像、上传和拉取镜像、管理镜像、管理容器实例、运行容器等。

### 2.2 容器编排

集群管理工具（编排工具）能够帮助用户以集群的方式在主机上启动容器，并能够实现相应的网络互联，同时提供负载均衡、可扩展、容错和高可用等保障。

当前关注度和使用率比较高的几种容器编排平台主要包括 Kubernetes、Apache Mesos、Docker Swarm、OpenShift、Rancher 等。

### 2.3 微服务

微服务就是将一个完整应用中所有的模块拆分成多个不同的服务，其中每个服务都可以独立部署、维护和扩展，服务之间通常通过 RESTful API 通信，这些服务围绕业务能力构建，且每个服务均可使用不同的编程语言和不同的数据存储技术。

第一代微服务是以 Dubbo、Spring Cloud 为代表的微服务治理框架，但该类框架并不能很好地解决微服务的调用依赖、版本迭代、安全性、可观测性等问题；第二代微服务治理框架为服务网格，该类框架解决了大部分开发人员在使用 Spring Cloud 时遇到的不足和痛点。

### 2.4 服务网格

服务网格通常通过一组轻量级网络代理实现，这些代理与应用程序一起部署，而无须感知应用程序本身。目前服务网格以 Istio 为代表。

### 2.5 Serverless

Serverless 可在不考虑服务器的情况下构建并运行应用程序和服务，它使开发者避免了基础设施管理，如集群配置、漏洞修补、系统维护等。Serverless 并非字面理解的不需要服务器，只是服务器均交由第三方管理。

Serverless 通常可分为两种实现方式，即 BaaS（Backend as a Service，后端即服务）和 FaaS（Functions as a Service，函数即服务），其中 FaaS 是 Serverless 的主要实现方式。FaaS 即开发者编写一段代码，并定义何时以及如何调用该函数，随后该函数在云厂商提供的服务端运行，在此过程中开发者只需编写并维护一段功能代码。

### 2.6 DevOps

开发运营一体化（DevOps）全称为 Development & Operations。

云原生倡导敏捷、容错、自动化的特点，使得 DevOps 成为云原生基础不可或缺的一环：

1. 云原生提供 DevOps 基础设施
2. 微服务架构加速 DevOps 的应用
3. DevOps 赋能服务网格
4. DevOps 加速 Serverless 应用迁移

# 二、云原生技术的风险分析

## 3 容器基础设施的风险分析

### 3.1 容器基础设施面临的风险

#### 容器镜像存在的风险

1. 不安全的第三方组件
2. 大肆传播的恶意镜像
3. 极易泄露的敏感信息

#### 活动容器存在的风险

1. 不安全的容器应用
2. 不受限制的资源共享
3. 不安全的配置与挂载

通过简单的配置和挂载，容器的隔离性将被轻易打破。例如：

- 通过配置 --privileged 选项，容器将不受 Seccomp 等安全机制的限制，容器内 root 权限将变得与宿主机上的 root 权限无异。
- 通过配置 --net=host，容器将与宿主机处于同一网络命名空间（网络隔离打破）。
- 通过配置 --pid=host，容器将与宿主机处于同一进程命名空间（进程隔离打破）。
- 通过执行挂载 --volume /:/host，宿主机根目录将被挂载到容器内部（文件系统隔离被打破）。

#### 容器网络存在的风险

每个容器都处于由 docker0 网桥构建的同一局域网内，彼此之间互相连通。

#### 容器管理程序接口存在的风险

Socket 是 Docker 守护进程接收请求及返回响应的应用接口。Docker 守护进程主要监听两种形式的 Socket：UNIX socket 和 TCP socket。安装完成并启动后，Docker 守护进程默认只监听 UNIX socket。

1. UNIX socket：Docker 守护进程默认以宿主机 root 权限运行。只要能够与该 UNIX socket 进行交互，就可以借助 Docker 守护进程以 root 权限在宿主机上执行任意命令。
2. TCP socket：默认情况下对 Docker 守护进程 TCP socket 的访问时加密且无认证的，端口一般为 2375。命令 `docker -H tcp://your-ip:2375 ps` 能够列出指定主机上的所有活动容器。

#### 宿主机操作系统存在的风险

与虚拟机不同，作为一种轻量级虚拟化技术，容器通常与宿主机共享内核。如果宿主机内核本身存在安全漏洞，理论上，这些漏洞是能够在容器内进行利用的。通过利用这些漏洞，攻击者可能实现权限提升、甚至从容器中逃逸，获得宿主机的控制权。

例如，在存在 CVE-1026-5195（“脏牛”）漏洞的容器环境中，攻击者可以借助该漏洞向进程 vDSO 区域写入恶意代码，从而实现容器逃逸。

#### 无法根治的软件漏洞

例如 CVE-2019-14271、CVE-2019-5736 等漏洞能够导致容器逃逸。

### 3.2 针对容器化开发测试过程的攻击案例

#### 背景知识

1. docker cp 命令：用于在 Docker 创建的容器与宿主机文件系统之间进行文件或目录复制。
2. 符号链接：ln 命令能够创建一个符号链接，`ln -s target_path link_path`。

#### CVE-2018-15664：符号链接替换漏洞

在 18.06.1-ce-rc2 版本之前的 Docker 中，docker cp 命令对应的后端 API 存在基于竞争条件的符号链接替换漏洞，能够导致目录穿越。攻击者可利用此漏洞以 root 权限实现宿主机文件系统的任意读写。

#### CVE-2019-14271：加载不受信任的动态链接库

在 19.03.x 及若干非正式版本的 Docker 中，docker cp 命令依赖的 docker-tar 组件会加载容器内部的 nsswitch 动态链接库，但自身却未被容器化，攻击者可通过劫持容器内的 nsswitch 动态链接库来实现对宿主机进程的代码注入，获取宿主机上 root 权限的代码执行能力。

### 3.3 针对容器软件供应链的攻击案例

#### 镜像漏洞利用

镜像漏洞利用指的是镜像本身存在漏洞时，使用镜像创建并运行的容器也通常会存在相同漏洞，攻击者利用镜像中存在的漏洞去攻击容器。

例如，轻量化 Linux 发行版  Alpine 曾经曝出过一个漏洞 CVE-2019-5201。在 3.3~3.9 版本的 Alpine 镜像中，root 用户密码被设置为空，攻击者可能在攻入容器后借此提升到容器内部 root 权限。

#### 镜像投毒

根据目的不同，常见的镜像投毒有三种类型：投放恶意挖矿镜像、投放恶意后门镜像和投放恶意 exploit 镜像。

### 3.4 针对运行时容器的攻击案例

#### 容器逃逸

##### 不安全配置导致的容器逃逸

- 当操作者执行 docker run --privileged 时，Docker 将允许容器访问宿主机上的所有设备，同时修改 AppArmor 或 SELinux 的配置，使容器拥有与那些直接运行在宿主机上的进程几乎相同的访问权限。

##### 不安全挂载导致的容器逃逸

- Docker Socket 是 Docker 守护进程监听的 UNIX 域套接字，用来与守护进程通信，查询信息或下发命令。如果在攻击者可控的容器内挂在了该套接字文件（/var/run/docker.sock），将会导致容器逃逸。
- procfs 是一个伪文件系统，它动态反映着系统内进程及其他组件的状态，其中有许多非常敏感、重要的文件。因此，将宿主机的 procfs 挂载到不受控的容器中也是十分危险的，尤其是在该容器内默认启用 root 权限，且没有开启 User Namespace 时。

##### 相关程序漏洞导致的容器逃逸

- CVE-2019-5736：覆盖宿主机上的 runC 文件

##### 内核漏洞导致的容器逃逸

- CVE-2016-5195：内存页的写时复制问题

#### 安全容器逃逸

Kata Containers 是一种安全容器的具体实现，其他主流的安全容器还有 Google 推出的 gVisor 项目等。其核心思想是为每一个容器运行一个独立虚拟机，从而避免其与宿主机共享内核。如果 Kata Containers 内部的攻击者想要逃逸到宿主机上，必须至少经过两次逃逸——容器逃逸和虚拟机逃逸。

- CVE-2020-2023：Kata Containers 容器不受限地访问虚拟机的根文件系统设备。
- CVE-2020-2024：Kata-Containers 运行时（runtime）在卸载（unmount）挂载点时存在符号链接解析漏洞，可能允许针对宿主机的拒绝服务攻击。
- CVE-2020-2025：基于 Cloud Hypervisor 的 Kata Containers 会将虚拟机文件系统的改动写入到虚拟机镜像文件（在宿主机上）。
- CVE-2020-2026：Kata Containers 运行时在挂载（mount）容器根文件系统（rootfs）时存在符号链接解析漏洞，可能允许攻击者在宿主机上执行任意代码。

#### 资源耗尽型攻击

容器运行时默认情况下并未对容器内进程在资源使用上做任何限制，以 Pod 为基本单位的容器编排管理系统在默认情况下同样未对用户创建的 Pod 做任何 CPU、内存使用限制。

缺乏限制使得云原生环境面临资源耗尽型攻击的风险。攻击者可能通过在一个容器内发起拒绝服务来占用大量宿主机资源，从而影响到宿主机自身或宿主机上其他容器的正常运行。

常见容易受影响的资源如下：

1. 计算资源：CPU、内存等。
2. 存储资源：本地硬盘等。
3. 软件资源：内核为何的数据结构等。
4. 通信资源：网络带宽等。

## 4 容器编排平台的风险分析

### 4.1 容器编排平台面临的风险

例如，一个常见的 Kubernetes 集群，由一个 Master 节点和三个 Worker 节点组成，Pod 之间借助 CNI 插件 Flannel 实现通信。Kubernetes 自身的系统 Pod（kube-system 命名空间内的 Pod）主要运行在 Master 节点上，除此之外，每个 Worker 节点上页分别有一个 Flannel Pod 和 kube-proxy Pod；所有业务 Pod 分布在三个 Worker 节点上。另外，每个节点上还有一个 Kubelet 服务，负责管理容器。

编排系统和容器之间并非完全独立，例如，我们在 Kubernetes 集群中需要以 YAML 声明式文件的形式来创建 Pod，而 Pod 只是一个逻辑上的概念，实际由一个或多个容器组成。对容器的配置须以 Pod 的配置方式下发。

#### 容器基础设施存在的风险

- 镜像面临的风险与前文中不安全的第三方组件、大肆传播的恶意镜像和极易泄露的敏感信息三个方面的分析结果基本相同。
- 活动容器面临的风险与前文中不安全的容器应用、不受限制的资源共享和不安全的配置与挂载三个方面的分析结果基本一致。
- 在没有特别指定网络访问控制策略的情况下，各 Pod 之间互通，Kubernetes 网络存在的风险与前文中容器网络存在的风险基本相似。
- 容器管理程序接口存在的风险应在 Kubernetes 组件接口风险的范畴中。目前，Kubernetes+Docker 的搭配仍然是主流，因此，Docker 守护进程的接口风险在 Kubernetes 环境中仍然存在。
- 对于 Kubernetes 来说，宿主机操作系统存在的凤霞主要与容器相关，此外，容器的软件漏洞应被考虑在 Kubernetes 的软件漏洞当中。

#### Kubernetes组件接口存在的风险

Kubernetes 中组件众多，绝大多数组件以基于 HTTP 或 HTTPS 的 API 形式提供服务。

| 组件       | 默认端口 | 说明                                  |
| ---------- | -------- | ------------------------------------- |
| API Server | 6443     | 基于 HTTPS 的安全端口                 |
| API Server | 8080     | 不安全的 HTTP 端口，不建议启用        |
| Kubelet    | 10248    | 用于检查 Kubelet 健康状态的 HTTP 端口 |
| Kubelet    | 10250    | 面向 API Server 提供服务的 HTTPS 端口 |
| Dashboard  | 8001     | 提供 HTTP 服务的端口                  |
| etcd       | 2379     | 客户端与服务端之间通信的端口          |
| etcd       | 2380     | 不同服务端实例之间通信的端口          |

##### API Server

默认情况下，API Server 在 8080 和 6443 两个端口上提供服务。

8080 端口提供的时没有 TLS 加密的 HTTP 服务，且所有到达该端口的请求将绕过所有认证和授权模块（但是仍然会被准入控制模块处理）。如果将该端口暴露在互联网上，那么任何网络可达的攻击者都能够通过该端口直接与 API Server 交互，进而控制整个集群。

6443 端口提供的是使用 TLS 加密的 HTTPS 服务，到达的请求必须通过认证和授权机制才能够被成功处理。在认证和授权机制配置正确的情况下，6443 端口提供的服务安全性会更高。

##### Dashboard

如果直接将 Dashboard 端口映射在宿主机节点上，或者在执行 kubectl proxy 时指定了额外地址参数，那么所有能够访问到宿主机的用户，包括攻击者，都将能够直接访问 Dashboard。

```
kubectl proxy --address 0.0.0.0 --accept-hosts='^*$'
```

默认情况下 Dashboard 需要登录认证，但是，如果用户在 Dashboard 的启动参数中添加了 --enable-skip-login 选项，那么攻击者就能够直接点击 Dashboard 界面的”跳过“按钮，无须登录便可直接进入 Dashboard。

##### Kubelet

默认配置下，Kubelet 在 10250 端口开放上述 API 服务，另外还监听 10248 端口，以供其他组件检查 Kubelet 的运行状态：

```
curl http://localhost:10248/healthz
```

10248 端口的服务相对简单，不存在特别的风险，但 10250 端口却未必。默认情况下，API Server 在访问 Kubelet 的 API 时需要使用客户端证书，相对来说较安全。但如果出现以下任一情况：

1. 攻击者通过某种方式窃取了 API Server 访问 Kubelet 的客户端证书。
2. 用户为了方便起见，将 Kubelet 的 --anonymous-auth 参数设置为 true，且 authorization mode 设置为 AlwaysAllow。

则网络可达的攻击者都能够直接与 Kubelet 进行交互，从而实现对其所在节点的控制。

##### etcd

Kubernetes 集群内的各种资源及其状态均存储在 etcd 中。如果能有办法读取 etcd 中的数据，就可能获取高权限，从而控制集群。目前，etcd 启动后监听 2379 和 2380 两个端口，前者用于客户端连接，后者用于多个 etcd 实例之间的对端通信。在多节点集群中，为了实现高可用，etcd 往往在节点 IP 上（非本地 IP）监听，以实现多节点之间的互通，这可能允许外部攻击者访问 etcd。

默认情况下，两个端口提供的服务都需要相应证书才能访问（禁止匿名访问），这为 etcd 的安全性提供了保障。如果攻击者窃取了证书，或者用户将 etcd 设置为允许匿名访问，那么攻击者就可能直接访问 etcd 并窃取数据（利用 etcdctl 工具）：

```
./etcdctl --endpoints=https://127.0.0.1:2379 --cacert ./etcd/ca.crt --cert ./apiserver-etcd-client.crt --key ./apiserver-etcd-client.key get /registry/serviceaccounts/kube-system/default -o json
```

#### 集群网络存在的风险

为了实现集群 Pod 间相互通信，在安装部署 Kubernetes 后，还要额外安装一个网络插件，常见的网络插件有 Flannel、Calico 和 Cilium 等。

在没有其他网络隔离策略和 Pod 安全策略的默认情况下，由于 Pod 与 Pod 之间彼此可联通，且 Pod 内的 root 用户具有 CAP_NET_RAW 权限，集群内部可能发生网络探测、嗅探、拒绝服务和中间人攻击等网络攻击。

#### 访问控制机制存在的风险

Kubernetes 中的访问控制机制主要由认证机制、授权机制和准入机制三个部分组成，每一个部分通常会有一种或多种具体的实现机制可供选择。

#### 无法根治的软件漏洞

Kubernetes 也被曝出过许多安全漏洞。

### 4.2 针对Kubernetes的组件不安全配置攻击案例

#### Kubernetes API Server未授权访问

在一个 Kubernetes 集群中，各组件通过 API Server 进行交互。

默认情况下，API Server 能够在两个端口上对外提供服务：8080 和 6443，前者以 HTTP 提供服务，无认证和授权机制；后者以 HTTPS 提供服务，支持认证和授权服务。

在较新版本的 Kubernetes 中，8080 端口的 HTTP 服务默认不启动。然而，如果用户在 /etc/kubernetes/mannifests/kube-apiserver.yaml 中将 --insecure-port=0 修改为 --insecure-port=8080 并重启 API Server，那么攻击者只要网络可达，都能够通过此端口操控集群。

直接远程列出目标及其上运行的 Pod：

```
# kubectl -s your-ip:8080 get pod
```

还能够创建一个挂载宿主机目录的 Pod 进行容器逃逸，进一步尝试获得宿主机权限。

#### Kubernetes Dashboard未授权访问

Kubernetes Dashboard 是一个基于 Web 的 Kubernetes 用户界面，可以用它来在集群中部署、调试容器化应用，或者管理集群资源。借助 Dashboard，能够获得当前集群中应用运行状态的概览，创建或修改 Kubernetes 资源，如 Deployment、Job、DaemonSet 等。我们能够扩展 Deployment、执行滚动升级、重启 Pod 或在部署向导的辅助下部署新应用。

根据官方文档，用户可以使用以下命令部署 Dashboard：

```
kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.4/aio/deploy/recommand.yaml
```

Dashboard 需要配置 token 才能够访问，然而提供了“跳过”（Skip）选项。从 1.10.1  版本起，Dashboard 默认禁用了“跳过”按钮。然而，如果用户在运行 Dashboard 时添加了 --enable-skip-login，那么攻击者只要网络可达，就能进入 Dashboard。

使用上面的 recommand.yaml 创建 Dashboard 是可靠的。即使攻击者“跳过”认证直接登录，也几乎没有办法操作。

#### Kubelet未授权访问

在一个 Kubernetes 集群中，Kubelet 是主要的“节点代理”，运行在集群的每个节点上，它负责向 API Server 注册所在节点。

与 Kubernetes API Server 类似，Kubelet 同样运行着 API 服务（默认在 10250 端口），集群中其他组件可以通过调用 API 来改变集群状态，比如启动和停止 Pod。API 服务可能会存在未授权访问的问题。

Kubelet 的配置文件是 /var/lib/kubelet/config.yaml。一般来说，我们在安装 Kubernetes 时会将 --anonymous-auth 设置为 false，并在 authorization 中选择 mode 为 Webhook。前一选项禁止匿名用户访问，后一选项则使 Kubelet 通过 API Server 进行授权（即使匿名用户能够访问，也几乎不具备任何权限）。

如果将 --anonymous-auth 设置为 true，并在 authorization 中选择 mode 为 AlwaysAllow，那么攻击者可以列出正在运行的 Pod，还可以对任意 Pod 执行命令，从而提升权限。

一种思路：

- 对 Kubernetes API Server 的 Pod 执行读取敏感凭证的命令，读取凭证可获得高权限身份，然后利用该身份与 Kubernetes API Server 交互并创建新的 Pod，从而逃逸出容器。

### 4.3 针对Kubernetes的权限提升攻击案例

CVE-2018-1002105 是一个 Kubernetes 的权限提升漏洞，允许攻击者在拥有集群内低权限的情况下提升权限至 Kubernetes API Server 权限，所有低于 v1.10.11、v1.11.5、v.1.12.3 版本的 Kubernetes 均受影响。

通过构造一个特殊的请求，攻击者能够借助 Kubernetes API Server 作为代理，建立一个到后端服务器的连接，进而以 Kubernetes API Server 的身份向后端服务器发送任意请求，实质上就是权限提升。

### 4.4 针对Kubernetes的拒绝服务攻击案例

近年来曝光的三个可以导致 Kubernetes API Server 拒绝服务的安全漏洞：

- CVE-2019-11253：YAML 解析问题
- CVE-2019-9512/CVE-2019-9514：Kubernetes 依赖的 Go 语言 HTTP/2 库的问题

### 4.5 针对Kubernetes网络的中间人攻击案例

在默认配置下的 Kubernetes 集群中，假如攻击者借助 Web 渗透等方式攻破了某个 Pod，就有可能针对集群内的其他 Pod 发起中间人攻击，甚至可以基于此实现 DNS 劫持。

以下是一个发生在云原生环境中的 ARP 欺骗（ARP Spoofing）和 DNS 劫持（DNS Hijacking）场景：

- 攻击者攻破 Web App Pod 之后，获得容器内部的 root 权限，通过 ARP 欺骗诱导另一个 Pod（如 Backend Pod），让其以为 Web App Pod 是集群的 DNS 服务器，进而使得 Backend Pod 在对外发起针对某域名（如 example.com）的 HTTP 请求时首先向 Web App Pod 发起 DNS 查询请求。
- 攻击者在 Web App Pod 内部设置的恶意 DNS 服务器收到查询请求后返回了自己的 IP 地址，Backend Pod 因此以为 example.com 域名的 IP 地址是 Web App Pod 的地址，于是向 Web App Pod 发起 HTTP 请求。
- 在收到 HTTP 请求后，攻击者在 Web App Pod 内设置的恶意 HTTP 服务器返回恶意响应给 Backend Pod。

整个攻击过程结束，Backend Pod 拿到的并不是正确的信息。

## 5 云原生应用的风险分析

由于云原生应用具备高度弹性化、可扩展、可移植等特点，现今大多数企业已纷纷将其应用从传统的单体架构转向微服务架构，云计算模式也相应地从 IaaS 转向 CaaS 和 FaaS（Function as a Service，函数即服务）。

### 5.1 云原生应用风险概述

提出三个观点，有助于理解本章内容。

**观点一：云原生应用继承了传统应用的风险和 API 的风险**

云原生应用源于传统应用，因而云原生应用也就继承了传统应用的风险。此外，云原生应用架构的变化导致应用 API 交互增多，可以说云原生应用中大部分交互模式已从 Web 请求/响应转向各类 API 请求/响应，如 RESTful/HTTP、gRPC 等，因此 API 风险也进一步提升。

**观点二：应用架构变革将会带来新的风险**

由于应用架构变革，云原生应用遵循面向微服务化的设计方式，导致功能组件化、服务数量激增、配置复杂等问题，从而为云原生应用和业务带来新的风险。

**观点三：计算模式变革将会带来新的风险**

随着云计算的不断发展，企业在应用微服务化后，会进一步聚焦于业务自身，并将功能函数化，因而出现了无服务计算（Serverless Computing）这类新的云计算模式，并引入了 Serverless 应用和 Serverless 平台的新风险。

### 5.2 传统应用的风险分析

传统应用的风险以 Web 应用风险为主，主要包含注入、敏感数据泄露、跨站脚本、使用含有已知漏洞的组件、不足的日志记录和监控等风险。

API 风险主要包含安全性错误配置和注入、资产管理不当、资源缺失和速率限制等风险。

### 5.3 云原生应用的新风险分析

新应用架构遵循服务化的设计模式，通过应用的微服务化，能够构建容错性好、易于管理的松耦合系统。应用架构变化带来的新风险：

1. 机密性受损的风险：典型的如信息泄露风险，攻击者可通过利用资产脆弱性和嗅探、暴力破解等攻击方式窃取用户隐私数据，造成信息泄露。
2. 完整性受损的风险：典型的如未授权访问风险，攻击者可通过利用资产脆弱性和中间人攻击等行为绕过系统的认证授权机制，执行越权操作，进行未授权的访问。
3. 可用性受损的风险：典型的如系统受拒绝服务攻击的风险，一方面，攻击者可通过畸形报文、SYN 泛洪等攻击方式为目标系统提供非正常服务；另一方面，系统供不应求的场景也会导致系统遭受拒绝服务攻击风险。

#### 数据泄露的风险

1. 应用漏洞：通过资产漏洞对应用数据进行窃取。
2. 密钥不规范管理：通过不规范的密钥管理对应用数据进行窃取。
3. 应用间通信未经加密：通过应用间通信未经加密的缺陷对传输中数据进行窃取，进而升级到对应用数据的窃取。

#### 未授权访问的风险

1. 应用漏洞带来的风险：未授权访问漏洞非常多，例如 Redis、MongoDB、Jenkins、Docker、Zookeeper、Hadoop 的相关漏洞。
2. 访问权限错误配置带来的风险：微服务应用框架下，权限映射关系变得更加复杂，相应的权限配置难度也在同步增加。

#### 拒绝服务的风险

1. 应用漏洞带来的风险：如 ReDoS（Regular expression Denial of Service）漏洞、Nginx 拒绝服务漏洞等。
2. 访问需求与资源能力不匹配带来的风险：微服务应用框架下，API 数量会随着服务数量的递增而递增，当外部访问量突增时，可能导致访问需求与资源能力不匹配的问题，使服务端无法对请求做出及时的响应，造成页面卡死，进而引起系统崩溃。

### 5.4 云原生应用业务的新风险分析

云原生应用风险主要是 Web 应用风险，即网络层面的风险。而云原生应用业务风险无明显的网络攻击特征，多是利用业务系统的漏洞或规则对业务系统进行攻击来牟利，从而造成一定的损失。

#### 未授权访问的风险

1. 业务参数异常带来的风险
2. 业务逻辑异常带来的风险

#### API滥用的风险

此类风险通常指的是攻击者对业务系统的“薅羊毛”操作，风险成因是业务频率异常。

业务频率异常主要指针对一个或一组 API 的频繁调用。

### 5.5 Serverless的风险分析

#### Serverless特征带来的风险

1. 输入源的不确定性带来的风险
2. 服务器托管云服务商带来的风险
3. 供应商锁定带来的风险

#### Serverless应用风险

可参考《OWASP Serverless 应用十大风险报告》。

#### Serverless平台风险

Serverless 平台主要指 FaaS 平台。类似在 IaaS 平台上运行虚拟机、在 PaaS 上运行操作系统和应用，FaaS 平台上运行的是一个个 Serverless 函数。

目前主流的 FaaS 平台分为两种类型：一种是面向公有云提供商的 FaaS 平台，常见的有 AWS Lambda、Microsoft Azure Functions、Google Cloud Functions 等；另一种是面向私有云的 FaaS 平台，此类以开源项目居多，且均支持在 Kubernetes 上进行部署，常见的有 Apache OpenWhisk、Kubeless、OpenFaaS、Fission 等。

与其他云计算模式不同的是，Serverless 为 FaaS 平台引入了新的攻击源。

1. 未授权访问的风险
2. 数据泄露的风险
3. FaaS平台账户的风险

#### Serverless被滥用的风险

Serverless 被滥用指攻击者通过恶意构建 Serverless 函数并利用其充当整个攻击中的一环，这种方式可在一定程度上规避安全设备的检测。

导致 Serverless 被滥用的原因主要包括以下几点：

1. 云厂商提供 Serverless 函数的免费使用。
2. 用户部署 Serverless 函数的成本低。
3. Serverless 函数访问域名可信。

一个具体的攻击场景：攻击者通过在受害者的主机上投放木马，从而实现对受害者主机的控制，其中攻击者为实现攻击资产的隐蔽性，采用了公有云 Serverless 函数作为请求中转。

攻击流程分为四个步骤：

1. 受害者主机中的木马程序被执行，该木马会向攻击者主机发起请求以建立连接。
2. 攻击者通过构造 Serverless 函数作为受害者主机和攻击者主机间的中转机，该 Serverless 函数负责将木马中的上线包发送至攻击者主机。
3. 攻击者主机收到来自 Serverless 函数的请求，与受害者主机成功建立连接，并在响应中附带控制受害者主机的命令。
4. 公有云 Serverless 函数收到攻击者主机的响应，并将执行命令发送至受害者主机的木马程序中，从而实现对受害者主机的远程操作。

## 6 典型云原生安全事件

1. 特斯拉 Kubernetes 挖矿事件
2. 微软监测到大规模 Kubernetes 挖矿事件
3. Graboid 蠕虫挖矿传播事件

## 7 监控

### 7.1 监控工具

#### CAdvisor 和 Heapster

CAdvisor 是 Google 开源的一个收集容器资源使用情况的监控工具，是 Kubelet 内置的容器资源收集工具。它可以自动发现给定节点中的所有容器，并收集 CPU、内存、文件系统和网络使用情况等统计信息，并对外提供 CAdvisor 原生的 API。

CAdvisor 是监控数据的采集器，本身并不提供任何长期存储或分析功能，而且它仅会收集基本资源利用率。在 Kubernetes 中，节点的 Kubelet 可以安装 cAdvisor 来监控 Pod 容器资源。

为了进一步处理这些数据，需要对 cAdvisor 采集到的数据进行收集和管理，通常使用 Heapster 实现。Heapster 是容器集群监控和性能分析工具，支持 Kubernetes。Heapster 将每个节点上的 cAdvisor 数据进行汇总，然后导入后端的存储中（如 InfluxDB），并且可以进一步实现可视化（如 Grafana）。

Heapster 就像任何应用程序一样，在集群中作为 Pod 运行。Heapster Pod 从 Kubelet 中获取有用数据，而 Kubelet 本身的数据则是从 cAdvisor 中得到，然后 Heapster 将信息分组，其中也包括相关标签。

#### Prometheus

Prometheus（普罗米修斯）是 SoundCloud 公司的一套开源系统监控和告警框架，采用多维数据模型，其中包含通过指标名称和键/值对标识的事件序列数据，以及灵活的查询语言 PromQL 实现这种多维度的数据检索。同时，它不依赖分布式存储，单个节点是自治的，通过基于 HTTP 的 pull 方式采集时序数据，也可以通过中间网关进行时间序列数据推送（pushing）。

其中主要包括 Prometheus Server、Pushgateway、Exporters、Alertmanager 等组件，其中 Prometheus Server 是 Prometheus 的主服务，主要用于数据的采集和存储、PromQL 查询、报警配置等；Pushgateway 用作批量、短期监控指标数据的推送总节点；Exporters 是各种汇报数据的导出器，如汇报机器数据的 node_exporter、汇报 MongoDB 信息的 MongoDB_exporter 等；Alertmanager 是用于告警的处理。

Prometheus 整体的流程比较简单，它可以直接接收或者通过中间的 Pushgateway 被动获取指标数据，在本地存储所有获取的指标数据，并对这些数据进行一些规则整理，生成一些聚合数据或者报警信息，可以使用 Grafana 或者其他一些工具来可视化这些数据。